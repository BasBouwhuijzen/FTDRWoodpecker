---
title: "assignment1_judith"
author: "j. van der Wolf"
date: "2024-11-25"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#library
library(tidyverse)
library(dplyr)

getwd()
#data
data <- read.csv("../Airbnb_Open_Data.csv")
```

#Datacleaning 
## Duplicates
```{r}
# Print total duplicates
sum(duplicated(data$host.id))

# Remove duplicate rows 
data <- data %>% 
  dplyr::distinct(host.id, .keep_all = TRUE)
```

## Subset & Rename
```{r}
# Subset data
data <- data %>%
  dplyr::select(cancellation_policy,
                room.type,
                Construction.year,
                service.fee,
                minimum.nights,
                number.of.reviews,
                reviews.per.month,
                review.rate.number,
                availability.365,
                price)

# Rename column names to snake_case format
data <- data %>%
  dplyr::rename(
    room_type = room.type,
    construction_year = Construction.year,
    service_fee = service.fee,
    minimum_nights = minimum.nights,
    number_of_reviews = number.of.reviews,
    reviews_per_month = reviews.per.month,
    review_rate_number = review.rate.number,
    availability_365 = availability.365,
    price_usd = price
  )
```

## Missing values
```{r}
# Count missing data
data %>%
  dplyr::summarise(across(everything(), ~ sum(is.na(.)))) %>%
  tidyr::pivot_longer(
    cols = everything(),
    names_to = "Variable",
    values_to = "NA Count"
  )
```

```{r}
# Drop all rows that contain empty or missing values
data <- data %>%
  # Convert empty character variables to NA
  mutate(across(where(is.character), ~ trimws(.))) %>%
  mutate(across(where(is.character), ~ na_if(., ""))) %>%
  
  # Drop records with NA values
  drop_na()
```

## Measurement level check and adjustment
```{r}
# Convert variables to factor types
data <- data %>%
  dplyr::mutate(
    cancellation_policy = factor(cancellation_policy, 
                                 levels = c("flexible", "moderate", "strict")),
    room_type = factor(room_type),
   review_rate_number_f = factor(review_rate_number,
                                 labels = c("one", "two", "three", "four", "five")))
   
# View new structure
str(data$cancellation_policy)
str(data$room_type)
str(data$review_rate_number_f)

is.factor(data$cancellation_policy)
is.factor(data$room_type)
```

```{r}
# Parse price numeric values
data <- data %>%
  dplyr::mutate(
    price_usd = parse_number(price_usd),
    service_fee = parse_number(service_fee)
  )
```

#Individual variables 

##construction_year
```{r}
(summary_constr <- data %>%
  summarise(min(construction_year),
            max(construction_year),
            median(construction_year)))

#reken uit hoeveel observaties er zijn voor elk jaartal
data %>% 
  count(construction_year)

#percentages
table(data$construction_year)/ nrow(data)

#omdat er maar 20 jaartallen zijn; bar-chart laat visueel beter zien vind ik. 
ggplot(data, aes(construction_year)) +
  geom_bar()

```

##service_fee
```{r}
summary(data$service_fee)
ggplot(data, aes(service_fee)) +
  geom_histogram(binwidth = 0.3)
```

##minimum_nights
```{r}
summary(data$minimum_nights)
#Extreme low value (negative = not possibe) and extreme high value (5645 = ingevuld om andere reden dan om aan te geven wat minimale nachten zijn - bijv. voor een periode niet verhuren, maar wel omhoog blijven komen in zoeksuggesties e.d.)

#counting negative values (10)
data %>% 
  count(minimum_nights < 0)

#counting high values => bigger than 1 year, 365 = 17 (bigger than 1/2 year = 93)
data %>% 
  count(minimum_nights > 365)

data %>%
  filter(between(minimum_nights, 0, 365)) %>%
   summarise(min(minimum_nights),
            max(minimum_nights),
            mean(minimum_nights))

data %>%
  filter(between(minimum_nights, 0, 365)) %>%
  ggplot(aes(minimum_nights)) +
  geom_histogram(binwidth = 0.3)

```

```{r}
cor(data$price_usd, data$service_fee)
```

We were wondering what service_fee was (in relation to price). We checked the correlation between those two variables and found that they almost perfectly correlated. Therefore we made the decision to remove the variable service_fee from analysis to avoid issues related to multicollinearity. 


```{r}
data_cleaned <- data %>%
  select(-service_fee) %>%
   filter(between(minimum_nights, 0, 365)) %>%
  filter(between(availability_365, 0, 365)) %>%
  filter(price_usd > 0) 

str(data)

```

Check regression 
```{r}
model1 <- lm(price_usd ~ construction_year, data_cleaned)
summary(model1)

#center construction_year 
data_cleaned <- data_cleaned %>%
  mutate(construction_year_c = construction_year - 2003)

model2 <- lm(price_usd ~ construction_year_c, data_cleaned)
summary(model2)

(ggplot1 <- ggplot(data_cleaned, aes(construction_year_c, price_usd)) +
  geom_point()) +
  stat_smooth(method = "lm")
```

```{r}
model3 <- lm(price_usd ~ review_rate_number_f, data_cleaned)
summary(model3)

model4 <-lm(price_usd ~ room_type, data_cleaned)
summary(model4)

(ggplot2 <- ggplot(data_cleaned, aes(review_rate_number_f, price_usd)) +
  geom_point()) +
  stat_smooth(method = "lm")
```
## Models
*Since the goal is to identify predictors in the dataset that can predict the price of an Airbnb, forward stepwise selection was used. We started with an empty model and predictors were systematically added one-at-a-time. We repeated the process until predictors could no further reduce the AIC, so a model with the best AIC statistic was found* 

```{r}
glimpse(data)
```


```{r}
glimpse(data2)
```

### Model 0
*The nullmodel only contains the intercept, which is the estimated average of price_usd: 626.668*
```{r}
# Define the null model (starting point)
model_null <- lm(price_usd ~ 1, 
                 data)

# Show model summary
summary(model_null)
```

### Forward Stepwise Selection approach
*Based on the forward stepwise selection approach that was used the first predictor in the model that is suggested, is 'reviews per month'.' The second predictor in the model that is suggested is 'construction year'. After these predictors are added to the model the model will not further improve according to this approach. However, when inspecting the small reductions in AIC the added predictors cause, the improvement is questioned* 
```{r}
# Perform forward step regression
model_forward <- step(
  model_null, 
  direction = "forward", 
  scope = formula(lm(price_usd ~ ., data)),
  trace = TRUE
)
```
### Model 2: Price predicted by reviews per month. 

*Based on the forward stepwise regression approach the first predictor that is added to the model is reviews_per_month. The estimated average price_usd is 625.0372 when reviews_per_month is held constant. When reviews_per_month increases with one unit, the estimated average price_usd increases with 1.1770. This positive relation however is not significant. The variance that is explained by reviews_per_month is extremely small (< .01), the AIC and MSE reduce slightly, but the BIC increases slightly, which suggests a worse model than the baseline. Also, The model deviance is 9041127940	 with p > .05, which indicates that this model does not significantly improve compared to the nullmodel.*

```{r}
model_2 <- lm(price_usd ~ 
                reviews_per_month,
              data = data)

summary(model_2)

#comparing model to nullmodel
compare_models(data,
              "price_usd",
              FALSE,
              model_null,
              model_2)
```

### Model 3: Price predicted by reviews per month and constructionyear. 

*Based on the forward stepwise regression approach the second and last predictor that is added to the model is constructionyear. The estimated average price_usd is 627.9384 when reviews_per_month and construction_year are held constant. When constructionyear increases with one unit, the estimated average price_usd decreases with 0.3066, when controlled for reviews_per_month. This negative relation however is not significant. When reviews_per_month increases with one unit, the estimated average price_usd increases with 1.1834. This positive realtion however is also not significant. The variance that is explained by both reviews_per_month and construction_year is still extremely small (< .01).* 

*The variance that is explained by reviews_per_month is extremely small (< .01). When comparing model 2 and 3 the results show no significant improvement of model 3 compared to model 2. The model deviance is 9040871201 with p > .05. Although the MSE decreases slightly, the AIC stays the same and the BIC increases.*

```{r}
model_3 <- lm(price_usd ~ 
                reviews_per_month +
                construction_year,
              data = data)

summary(model_3)

#Comparing model 2 to model 3
compare_models(data,
              "price_usd",
              FALSE,
              model_2,
              model_3)
```

### Model 4: Price predicted by reviews per month, constructionyear and room_type

*One more model was manually checked to determine whether the factor room_type was a predictor of price, after controlling for construction_year and reviews_per_month. Although we beforehand knew that this predictor would not improve the model, we wanted to add a categorical predictor with interaction effect to the analysis for the purpose of the assignment*

*The estimated average price_usd is 633.4169 for a review_rate_number of 1 when construction year and reviews_per_month are held constant. The estimated difference in average price_usd decreases with 2.5368 for a review_rate_number of 2, compared to a review_rate number of 1, for any construction year or reviews_per_month. However, estimated difference in average is not significant. The only significant estimated difference in average price_usd at an alphalevel of .05 is between review_rate_number 1 compared to review_rate_number of 5. The estimated difference in average price_usd decreases with 10.0145 for a review_rate_number of 5, compared to a review_rate number of 1, for any construction year or reviews_per_month.*  

*When adding an interaction to the model: construction_year and review_rate_number, the results show that there is a significant interaction effect between review_rate_number2 and construction year, which can be interpreted as follows: the strength and direction of the relation between construction_year and price_usd is depends on the review_rate_number, but only review rate number 2.* 

```{r}
#with categorical predictor
model_4 <- lm(price_usd ~ 
                reviews_per_month +
                construction_year +
                review_rate_number,
              data = data)

summary(model_4)

#with interaction effect 
model_5 <- lm(price_usd ~ 
                reviews_per_month +
                construction_year +
                review_rate_number +
                review_rate_number * construction_year,
              data = data)

summary(model_5)

#plot showing the interaction effect 
ggplot(data, aes(construction_year, price_usd, colour = review_rate_number)) +
  stat_smooth(se = FALSE)
```

*After manually checking the two models suggested by the forward stepwise regression approach, the conclusion was drawn that there were no significant predictors for price_usd in this dataset. For the purposes of this assignment however, we will continue with the best model identified by the forward stepwise regression approach: model 3 (price_usd predicted by construction_year and reviews_per_month). For this model, predictions were made about the significance of the regression, but we will now first check the assumptions of this model to check if we can use this model to predict future observations*

# Assumptions

## Visual inspection of Linearity and Homoscedasticity

*After visual inspection of the fitted versus residuals plot the conclusion is drawn that the assumption of linearity is met, because it seems that for any fitted value, the residuals seem to be centered roughly around 0, although there seem to be exceptions for the few fitted values > 650..*
*The assumption of homoscedasticity is harder to interpret, because almost all values are at the left of the plot, but the spread of those residuals does look the same. The few values on the right of the plot, which are far removed from the pattern, might be outliers*

```{r}
plot(fitted(model_3), resid(model_3), col = 'pink', pch = 20,
     xlab = "Fitted", ylab = "Residuals", main = "Data from Model_3")
abline(h = 0, col = "gray", lwd = 2)
```

## Formal testing of Homoscedasticity 

*According to the Breusch-Pagan test, the null-hypothesis "The errors have constant variance about the true model" is not rejected (BP= .989, p = .610), so the assumption of homoscedasticity is met.* 
```{r}
bptest(model_3)
```

## Visual inspection of Normality 

*After visual inspection of the histogram of residuals the conclusion is drawn that the assumption of linearity is violated. A QQ-plot was requested to further investigate the suspected non-normality of errors.The QQ-plot clearly shows a S-shape, which is an indication that the normal distribution has heavy 'tails' or more extreme values. Because of the large sample size, formal testing; like the Shapiro test, could not be executed. These tests are very sensitive when sample sizes exceed 5000.* 
```{r}
hist(resid(model_3),
     xlab   = "Residuals",
     main   = "Histogram of Residuals, model_3",
     col    = "darkorange",
     border = "dodgerblue",
     breaks = 200)

qqnorm(resid(model_3), col = "darkgrey")
qqline(resid(model_3), col = "dodgerblue", lwd = 2)
```

## Testing for multicollineairity 
*The reason why the this assumption is violated, might be due to the extreme amount of observations and the small range of construction year and reviews per month. This reason is expected, because when checking the correlation between those two items, it shows that they are almost uncorrelated (r = .006)*
```{r}
model_3 %>%
  VIF()
cor(data$reviews_per_month, data$construction_year)
```
## Influential observations 

### Outliers 
*Because the plot is not interpretable due to the extreme sample size, the choice was made to only display studentized residuals > 3, which is a common threshold for big datasets, however, there are no studentresiduals bigger than 3 and also no studentresiduals bigger than 2, which is a common threshold for small datasets. Therefor the conclusion was drawn that there are no clear outliers to worry about*
```{r}
model_3 %>%
  rstudent() %>%
  plot()

#Checking if there are student residuals bigger than 2
sum(abs(rstudent(model_3)) > 2)
```

### High leverage 
*in the leverage plot, several observations stand out from other observations. Because the dataset is so big, it is quite hard to identify how many and which observations these are, therefor we calculated the sum of large hatvalues. For small/normal samples the threshold of twice the mean hat value is commonly used, however, because of this large dataset we decided to use a threshold of 3 times the mean hat value. This indicated that there are 1907 points of large leverage.*  
```{r}
model_3 %>%
  hatvalues() %>%
  plot()

sum(hatvalues(model_3) > 3 * mean(hatvalues(model_3)))
```
### Influential Cases 
*The DFBETAS was used to check for influential, and possible problematic observations per regression coefficient. The choice was made to plot influential cases for the intercept, reviews_per_month and construction_year. After visual inspection of the plots we saw that the intercept showed several influential cases. We extracted cases > |.02| based on visual inspection of the dfbetas plot  There are 11 influential cases.*
*Based on visual inspection we also extracted infuential cases > |.05| for reviews per month. 6 influential cases were found.* *The influential cases found for reviewus per month overlap with the influential cases we found in price_usd*
*We did not find influential cases for construction year.*

```{r}
#dfbetasplot intercept
plot(dfbetas(model_3)[,1],
     main = "intercept")

#dfbetasplot reviews_per_month
plot(dfbetas(model_3)[,2],
     main = "reviews_per_month")

#dfbetasplot construction_year
plot(dfbetas(model_3)[,3],
     main = "construction_year")

#extracting outstanding values based on visual inspection of dfbetasplot
dfbetas_observations_intercept <- dfbetas(model_3)[, 1]
outstanding_observations_intercept <- dfbetas_observations_intercept[dfbetas_observations_intercept > 0.02 | dfbetas_observations_intercept < -0.02]
outstanding_observations_intercept

dfbetas_observations_reviews_per_month <- dfbetas(model_3)[, 2]
outstanding_observations_reviews <- dfbetas_observations_reviews_per_month[dfbetas_observations_reviews_per_month > 0.05 | dfbetas_observations_reviews_per_month < -0.05]
outstanding_observations_reviews


```
*We decided to remove 1907 points of large leverage and the influential cases. And to fit the model again to see how the coefficients would change and if this could improve the normality assumption.* 

```{r}
#removal of influential cases. 
rows_to_remove <- c(17809, 24049 ,38036 ,38230, 38479, 41516, 45820, 50503, 65703, 76161, 76692 )

#removal of large leverage 
hat_values <- hatvalues(model_3)
thresholdheadvalues <- 3 * mean(hat_values)
high_leverage_indices <- which(hat_values > thresholdheadvalues)


# Remove rows
data_minus <- data[-rows_to_remove, ]
data_minus <- data_minus[-high_leverage_indices,]

```
```{r}
model_3.1 <- lm(price_usd ~ 
                reviews_per_month +
                construction_year,
                data = data_minus)

summary(model_3.1)
summary(model_3)

#normalitycheck 
qqnorm(resid(model_3.1), col = "darkgrey")
qqline(resid(model_3.1), col = "dodgerblue", lwd = 2)
```

*Final conclusion* 
*After removal of the 1907 points of large leverage and the influential cases their was a slight change in coÃ«fficients noticable. The estimated average of price_usd was 627.8306 instead of 627.9384 in the original model when reviews_per_month and construction_year are held constant. When construction_year increases with one unit, the estimated average price_usd decreases with 0.2853 instead of 0.3066 like the original model, when controlled for reviews per month. This negative correlation is still not significant. When reviews_per_month increases with one unit, the estimated average price_usd increases with 1.1439 instead of 1.1834 like in the original model. This positive relation however is also not significant. The variance that is explained by both reviews_per_month and construction_year is still extremely small (< .01) and even smaller than the original model.*

*Although model meets the assumption of lineairity, homoscedasticity and independence of error and identified influential cases and points with large leverage were removed, this model can not be used to predict future price_usd for airbnb's. This is due to the violation of assumption of normality, which is less of a big problem for bigger samples, but is always wanted for predicting intervals.* 
