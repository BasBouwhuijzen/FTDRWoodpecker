---
title: "FTDR Assignment 1"
author: "Judith van der Wolf (4661672) Jesse Nieuwkoop (1689959) Jay de Jager () Bas Bouwhuijzen (2130616)"
date: "28-11-2024-"
output:
  html_document:
    toc: true
    toc_depth: 4
    toc_float:
      collapsed: false
      expand: 3
    df_print: paged
---

---

# Preparation

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Libraries

```{r}
# Import the libraries
library(tidyverse)    # For data manipulation
library(ggplot2)      # For plotting
library(ggpubr)       # For ggplot grid arrange
library(kableExtra)   # For fancy tables
library(lmtest)       # Assumption Checks
library(regclass)     # Assumption Checks
```

## Read data

```{r}
# Read data
data <- read.csv("Airbnb_Open_Data.csv")

# View data structure
dplyr::glimpse(data)
```

# Preprocessing

## Duplicates
*The data was checked for duplicates in host.id, because each host.id number should be unique in the dataset. 542 Host.id duplicates were found and removed.* 
```{r}
# Print total duplicates
sum(duplicated(data$host.id))
```

```{r}
# Remove duplicate rows 
data <- data %>% 
  dplyr::distinct(host.id, .keep_all = TRUE)
```

## Subset & Rename
*The choice was made to only include the variables cancellation policy, roomtype, constructionyear, servicefee, minimumnights, numberofreviews, reviewspermonth, reviewratenumber, availability365 as possible predictors of price.*
*Other variables in the dataset were either qualitative, such as complete written reviews or gpslocations of subareas in New York City, which we did not want to use for this analysis.* 
```{r}
# Subset data
data <- data %>%
  dplyr::select(cancellation_policy,
                room.type,
                Construction.year,
                service.fee,
                minimum.nights,
                number.of.reviews,
                reviews.per.month,
                review.rate.number,
                availability.365,
                price)

# Rename column names to snake_case format
data <- data %>%
  dplyr::rename(
    room_type = room.type,
    construction_year = Construction.year,
    service_fee = service.fee,
    minimum_nights = minimum.nights,
    number_of_reviews = number.of.reviews,
    reviews_per_month = reviews.per.month,
    review_rate_number = review.rate.number,
    availability_365 = availability.365,
    price_usd = price
  )
```

## Missing values

```{r}
# Count missing data
data %>%
  dplyr::summarise(across(everything(), ~ sum(is.na(.)))) %>%
  tidyr::pivot_longer(
    cols = everything(),
    names_to = "Variable",
    values_to = "NA Count"
  )
```
 *The decision was made to handle missing data with listwise deletion, which means excluding rows containing missing values from the analysis. This choice was made, because a complete dataset was prefered and it was possible, because the dataset contained over 60.000 observations* 
```{r}
# Drop all rows that contain empty or missing values
data <- data %>%
  # Convert empty character variables to NA
  mutate(across(where(is.character), ~ trimws(.))) %>%
  mutate(across(where(is.character), ~ na_if(., ""))) %>%
  
  # Drop records with NA values
  drop_na()
```

## Measurement level check

```{r}
# Convert variables to factor types
data <- data %>%
  dplyr::mutate(
    cancellation_policy = as.factor(cancellation_policy),
    room_type = as.factor(room_type),
    review_rate_number = as.factor(review_rate_number)
  )

# View new structure
str(data$cancellation_policy)
str(data$room_type)
str(data$review_rate_number)
```

```{r}
# Parse price numeric values
data <- data %>%
  dplyr::mutate(
    price_usd = parse_number(price_usd),
    service_fee = parse_number(service_fee)
  )
```

## Individual outlier removal

```{r}
# Store data before outlier removal for later comparison
data_pre_outlier_removal <- data
```

### Functions

#### capitalize_str()

```{r}
# Function to format column name to spaced, capitalized string
capitalize_str <- function(string) {
  # Replace underscores with spaces and capitalize each word
  formatted_name <- gsub("_", " ", string)
  formatted_name <- tools::toTitleCase(formatted_name)
  
  # Return result
  return(formatted_name)
}
```

#### summary_table_cat()

```{r}
# Function to display comparison summary table
summary_table_cat <- function(data1, data2 = NULL, variable, sort = "none") {
  # Summarize data1
  summary_data1 <- data1 %>%
    group_by(across(all_of(variable))) %>%
    summarise(
      `Frequency (Before)` = n(),
      `Percentage (Before)` = (n() / nrow(data1)) * 100
    )
  
  if (!is.null(data2)) {
    # Summarize data2 if provided
    summary_data2 <- data2 %>%
      group_by(across(all_of(variable))) %>%
      summarise(
        `Frequency (After)` = n(),
        `Percentage (After)` = (n() / nrow(data2)) * 100
      )
    
    # Merge summaries
    result <- full_join(summary_data1, summary_data2, by = variable) %>%
      mutate(
        `Percentage (Before)` = sprintf("%.2f%%", `Percentage (Before)`),
        `Percentage (After)` = sprintf("%.2f%%", `Percentage (After)`)
      )
    
    # Apply sorting
    if (sort == "asc") {
      result <- result %>% arrange(`Frequency (Before)`)
    } else if (sort == "desc") {
      result <- result %>% arrange(desc(`Frequency (Before)`))
    }
  } else {
    # For single dataset case
    result <- summary_data1 %>%
      mutate(
        `Percentage (Before)` = sprintf("%.2f%%", `Percentage (Before)`)
      ) %>%
      rename(`Frequency` = `Frequency (Before)`,
             `Percentage` = `Percentage (Before)`)
    
    # Apply sorting
    if (sort == "asc") {
      result <- result %>% arrange(Frequency)
    } else if (sort == "desc") {
      result <- result %>% arrange(desc(Frequency))
    }
  }
  
  # Rename the variable column
  result <- result %>%
    rename(!!capitalize_str(variable) := all_of(variable))
  
  # Display table
  result <- result %>%
    kbl() %>%
    kable_classic() %>%
    kable_styling(latex_options = c("striped"), full_width = F)
  
  # Return table
  return(result)
}

```

#### summary_table_nums()

```{r}
# Create function to create summary table for numerical variables
summary_table_nums <- function(data, variables) {
  # Compile summary table
  summary <- data.frame(
    Mean = sapply(variables, function(var) round(mean(data[[var]]), 3)),
    Min = sapply(variables, function(var) min(data[[var]])),
    Median = sapply(variables, function(var) median(data[[var]])),
    Max = sapply(variables, function(var) max(data[[var]])),
    SD = sapply(variables, function(var) round(sd(data[[var]]), 3))
  )
  
  # Temporarily rename rownames using capitalize_str
  rownames(summary) <- sapply(variables, capitalize_str)
  
  # Display summary table
  summary <- summary %>%
    kbl() %>%
    kable_classic(latex_options = c("striped"), full_width = TRUE)
  
  # Return table
  return(summary)
}
```

#### plot_histogram()

```{r}
# Function to create a histogram
plot_histogram <- function(data, variable, title = NULL, binwidth = NULL, bins = NULL) {
  
  # Compile plot
  plot <- ggplot(data, aes(x = .data[[variable]])) +
    geom_histogram(binwidth = binwidth, 
                   bins = bins, 
                   fill = "lightblue",
                   color = "black") +
    labs(
      title = title,
      x = capitalize_str(variable),
      y = "Frequency",
      fill = variable
    ) +
    theme_bw()
  
  # Return plot
  return(plot)
}
```

### General

```{r}
summary_table_nums(data, c("construction_year", 
                               "service_fee", 
                               "minimum_nights", 
                               "number_of_reviews", 
                               "reviews_per_month", 
                               "availability_365", 
                               "price_usd")
                   )
```

### Categorical variables

#### 1: cancellation_policy

```{r}
# Verify structure of factors
str(data$cancellation_policy)

# Verify levels of factors
levels(data$cancellation_policy)

# Verify if ordered
is.ordered(data$cancellation_policy)
```

```{r}
# Show summary table
(table_1_pre <- summary_table_cat(data, 
                                  variable = "cancellation_policy")
)
```

```{r}
# Show bar plot
(plot_1_pre <- ggplot(data) +
  geom_bar(aes(x = cancellation_policy, fill = cancellation_policy)) +
  scale_fill_manual(values = c("flexible" = "lightgreen", 
                               "moderate" = "lightblue", 
                               "strict" = "tomato")) +
  labs(title = "Bar Plot of Cancellation Policy",
       fill = "Type of Policy",
       x = "Type of Policy",
       y = "Frequency"
      ) +
  theme_bw()
)
```

#### 2: room_type

```{r}
# Verify structure of factors
str(data$room_type)

# Verify levels of factors
levels(data$room_type)

# Verify if ordered
is.ordered(data$room_type)
```

```{r}
# Show summary table
(table_2_pre <- summary_table_cat(data, 
                                  variable = "room_type", 
                                  sort = "desc")
)
```

```{r}
# Show bar plot
# https://www.learnui.design/tools/data-color-picker.html#palette
(plot_2_pre <- ggplot(data) +
  geom_bar(aes(x = fct_infreq(room_type,         # Sort on freq
                              ordered = FALSE),
               fill = room_type)) +
  scale_fill_manual(values = c("Entire home/apt" = "#58508d", 
                               "Private room" = "#ff6361", 
                               "Shared room" = "#ffa600",
                               "Hotel room" = "#bc5090")) +
  labs(title = "Bar Plot of Room Type",
       fill = "Type of Room",
       x = "Type of Room",
       y = "Frequency"
      ) +
  theme_bw()
)
```

#### 3: review_rate_number
*WE MOETEN IETS MET ORDERED: BESPREKEN MAANDAG, STEL VOOR OM VERIFY IF ORDERED ERUIT TE HALEN*
```{r}
# Verify structure of factors
str(data$review_rate_number)

# Verify levels of factors
levels(data$review_rate_number)

# Verify if ordered
is.ordered(data$review_rate_number)
```

```{r}
# Show summary table
(table_3_pre <- summary_table_cat(data, 
                                  variable = "review_rate_number")
)
```

```{r}
# Show bar plot
# https://www.learnui.design/tools/data-color-picker.html#divergent
(plot_3_pre <- ggplot(data) +
  geom_bar(aes(x = review_rate_number,
               fill = review_rate_number)) +
  scale_fill_manual(values = c("1" = "#de425b", 
                               "2" = "#fa9e5d", 
                               "3" = "#ffd582",
                               "4" = "#8bbe7a",
                               "5" = "#488f31")) +
  labs(title = "Before",
       fill = "Rate Number",
       x = "Rate Number",
       y = "Frequency"
      ) +
  theme_bw()
)
```

### Numerical variables

#### 4: construction_year
*The results show that constructionyear does not have a meaningfull nullpoint/referencepoint. Therefor the decision was made to center this variable in order to make more meaningfull interpretations in the analysis*

```{r}
# Plot histogram
(plot_4_pre <- plot_histogram(data, 
                              "construction_year", 
                              "Before",
                              binwidth = 1)
)

# Center construction_year
data <- data %>%
  mutate(construction_year = construction_year - 2003)
```

#### 5: service_fee
*After including service_fee as a possible predictor, the choice was made to check the correlation between servicefee and price, because it was suspected that servicefee could be a certain percentage of the total price. The correlation matrix showed indeed a correlation of .999. Therefore the decision was made to remove the variable service_fee from analysis to avoid issues related to multicollinearity.* 

```{r}
# Strong suspicion this is dependent on price_usd
cor(data$price_usd, data$service_fee)

#Remove service-fee from subset
data <- data %>%
  select(-service_fee)
```
#### 6: minimum_nights
*The results show some unrealistic values for minimumnights. There are a few values below 1 and a few values above 365. The values bigger than 365 might indicate that people don't want their room to be rented, but do want to keep appearing in the airbnb listing. This is a strategy sometimes used by host we read on the internet. Therefor, we decided to remove values below 1 and above 365.*

```{r}
# Plot histogram
(plot_6_pre <- plot_histogram(data, 
                              "minimum_nights", 
                              "Before",
                              binwidth = 3)
 )
```

```{r}
# Count values
sum(data$minimum_nights < 1)
sum(data$minimum_nights > 365)
```

```{r}
# Remove all values below 1 and above 365 from dataset
data <- data[data$minimum_nights >= 1 & data$minimum_nights <= 365, ]
```

#### 7: number_of_reviews

```{r}
# Plot histogram
(plot_7_pre <- plot_histogram(data, 
                              "number_of_reviews", 
                              "Before",
                              binwidth = 10)
)
```

#### 8: reviews_per_month
*The results show that there are several unrealistic values in the reviews_per_month variable. The decision was made to exclude all values above 45. We reasoned that 30-31 reviews per month was realistic (for each night per month), but that we should account for a margin of 15*. 

```{r}
# Plot histogram
(plot_8_pre <- plot_histogram(data, 
                              "reviews_per_month", 
                              "Before",
                              binwidth = 1)
)
```

```{r}
# View count of reviews_per_month values
data %>%
  count(reviews_per_month) %>%
  arrange(desc(reviews_per_month))
```

```{r}
# Remove values > 45 reviews_per_month
data <- data[data$reviews_per_month <= 45, ]
```

#### 9: availability_365
*The results show some unrealistic values for availability_365. The describtion of this variable is 'how many days per year the airbnb location is available'. Therefor we decided to remove negative values and values bigger than 365*

```{r}
# Plot histogram
(plot_9_pre <- plot_histogram(data, 
                              "availability_365", 
                              "Before",
                              binwidth = 7)
)
```

```{r}
# Count values
sum(data$availability_365 < 0)
sum(data$availability_365 > 365)
```

```{r}
# Remove values below 1 and above 365
data <- data[data$availability_365 >= 0 & data$availability_365 <= 365, ]
```

#### 10: price_usd

```{r}
# Plot histogram
(plot_10_pre <- plot_histogram(data, 
                               "price_usd", 
                               "Before",
                               binwidth = 10)
)
```

## Final variable inspection

### Categorical variables

#### 1: cancellation_policy

```{r}
# View summary comparison of cancellation_policy
summary_table_cat(data1 = data_pre_outlier_removal, 
                  data2 = data,
                  variable = "cancellation_policy")
```


#### 2: room_type

```{r}
# View summary comparison of room_type
summary_table_cat(data1 = data_pre_outlier_removal, 
                  data2 = data,
                  variable = "room_type")
```


#### 3: review_rate_number

```{r}
# View summary comparison of review_rate_number
summary_table_cat(data1 = data_pre_outlier_removal, 
                  data2 = data,
                  variable = "review_rate_number")
```


### Numerical variables

```{r}
summary_table_nums(data, c("construction_year", 
                           "minimum_nights", 
                           "number_of_reviews", 
                           "reviews_per_month", 
                           "availability_365", 
                           "price_usd")
                   )
```

#### 4: construction_year

```{r}
# Plot histogram after outlier removal
plot_4_post <- plot_histogram(data, 
                              "construction_year", 
                              "After",
                              binwidth = 1)

# Compare plots of before and after outlier removal
ggarrange(plot_4_pre, plot_4_post, ncol = 2, nrow = 1)
```

#### 6: minimum_nights

```{r}
# Plot histogram after outlier removal
plot_6_post <- plot_histogram(data, 
                              "minimum_nights", 
                              "After",
                              binwidth = 3)

# Compare plots of before and after outlier removal
ggarrange(plot_6_pre, plot_6_post, ncol = 2, nrow = 1)
```

#### 7: number_of_reviews

```{r}
# Plot histogram after outlier removal
plot_7_post <- plot_histogram(data, 
                              "number_of_reviews", 
                              "After",
                              binwidth = 10)

# Compare plots of before and after outlier removal
ggarrange(plot_7_pre, plot_7_post, ncol = 2, nrow = 1)
```

#### 8: reviews_per_month

```{r}
# Plot histogram after outlier removal
plot_8_post <- plot_histogram(data, 
                              "reviews_per_month", 
                              "After",
                              binwidth = 1)

# Compare plots of before and after outlier removal
ggarrange(plot_8_pre, plot_8_post, ncol = 2, nrow = 1)
```

#### 9: availability_365

```{r}
# Plot histogram after outlier removal
plot_9_post <- plot_histogram(data, 
                              "availability_365", 
                              "After",
                              binwidth = 7)

# Compare plots of before and after outlier removal
ggarrange(plot_9_pre, plot_9_post, ncol = 2, nrow = 1)
```

#### 10: price_usd

```{r}
# Plot histogram after outlier removal
plot_10_post <- plot_histogram(data, 
                              "price_usd", 
                              "After",
                              binwidth = 10)

# Compare plots of before and after outlier removal
ggarrange(plot_10_pre, plot_10_post, ncol = 2, nrow = 1)
```

# Linear Regression

## Functions

### compare_models()

```{r}
# Function to compare fit measures of multiple models
compare_models <- function(data, response_var, compare_with_first = FALSE, ...) {
  # Capture models and their names
  models <- list(...)
  model_names <- as.character(substitute(list(...)))[-1] # Extract model names
  num_models <- length(models)
  
  # Initialize variables to store results
  aic_vals <- numeric(num_models)
  bic_vals <- numeric(num_models)
  mse_vals <- numeric(num_models)
  r_squared <- numeric(num_models)
  deviance_rss <- c(NA, rep(NA, num_models - 1))
  deviance_pvalue <- c(NA, rep(NA, num_models - 1))
  
  # Loop through models to compute fit measures
  for (i in seq_along(models)) {
    aic_vals[i] <- AIC(models[[i]])
    bic_vals[i] <- BIC(models[[i]])
    mse_vals[i] <- mean(models[[i]]$residuals^2)
    r_squared[i] <- summary(models[[i]])$r.squared
    
    # Perform ANOVA tests
    if (compare_with_first && i > 1) {
      # Compare all models with the first model
      anova_test <- anova(models[[1]], models[[i]])
      deviance_rss[i] <- anova_test$RSS[2]
      deviance_pvalue[i] <- anova_test$`Pr(>F)`[2]
    } else if (i > 1) {
      # Compare each model with the previous model
      anova_test <- anova(models[[i - 1]], models[[i]])
      deviance_rss[i] <- anova_test$RSS[2]
      deviance_pvalue[i] <- anova_test$`Pr(>F)`[2]
    }
  }
  
  # Compile results into a tibble
  fit_measures <- tibble(
    Model = model_names,
    AIC = aic_vals,
    BIC = bic_vals,
    MSE = mse_vals,
    `R^2` = round(r_squared, 3),
    `Dev. RSS` = deviance_rss,
    `Dev. p-value` = deviance_pvalue
  )
  
  # Return fit measures
  return(fit_measures)
}
```

## Models
*Since the goal is to identify predictors in the dataset that can predict the price of an Airbnb, forward stepwise selection was used. We started with an empty model and predictors were systematically added one-at-a-time. We repeated the process until predictors could no further reduce the AIC, so a model with the best AIC statistic was found* 

```{r}
glimpse(data)
```


```{r}
glimpse(data2)
```

### Model 0
*The nullmodel only contains the intercept, which is the estimated average of price_usd: 626.668*
```{r}
# Define the null model (starting point)
model_null <- lm(price_usd ~ 1, 
                 data)

# Show model summary
summary(model_null)
```

### Forward Stepwise Selection approach
*Based on the forward stepwise selection approach that was used the first predictor in the model that is suggested, is 'reviews per month'.' The second predictor in the model that is suggested is 'construction year'. After these predictors are added to the model the model will not further improve according to this approach. However, when inspecting the small reductions in AIC the added predictors cause, the improvement is questioned* 
```{r}
# Perform forward step regression
model_forward <- step(
  model_null, 
  direction = "forward", 
  scope = formula(lm(price_usd ~ ., data)),
  trace = TRUE
)
```
### Model 2: Price predicted by reviews per month. 

*Based on the forward stepwise regression approach the first predictor that is added to the model is reviews_per_month. The estimated average price_usd is 625.0372 when reviews_per_month is held constant. When reviews_per_month increases with one unit, the estimated average price_usd increases with 1.1770. This positive relation however is not significant. The variance that is explained by reviews_per_month is extremely small (< .01), the AIC and MSE reduce slightly, but the BIC increases slightly, which suggests a worse model than the baseline. Also, The model deviance is 9041127940	 with p > .05, which indicates that this model does not significantly improve compared to the nullmodel.*

```{r}
model_2 <- lm(price_usd ~ 
                reviews_per_month,
              data = data)

summary(model_2)

#comparing model to nullmodel
compare_models(data,
              "price_usd",
              FALSE,
              model_null,
              model_2)
```

### Model 3: Price predicted by reviews per month and constructionyear. 

*Based on the forward stepwise regression approach the second and last predictor that is added to the model is constructionyear. The estimated average price_usd is 627.9384 when reviews_per_month and construction_year are held constant. When constructionyear increases with one unit, the estimated average price_usd decreases with 0.3066, when controlled for reviews_per_month. This negative relation however is not significant. When reviews_per_month increases with one unit, the estimated average price_usd increases with 1.1834. This positive realtion however is also not significant. The variance that is explained by both reviews_per_month and construction_year is still extremely small (< .01).* 

*The variance that is explained by reviews_per_month is extremely small (< .01). When comparing model 2 and 3 the results show no significant improvement of model 3 compared to model 2. The model deviance is 9040871201 with p > .05. Although the MSE decreases slightly, the AIC stays the same and the BIC increases.*

```{r}
model_3 <- lm(price_usd ~ 
                reviews_per_month +
                construction_year,
              data = data)

summary(model_3)

#Comparing model 2 to model 3
compare_models(data,
              "price_usd",
              FALSE,
              model_2,
              model_3)
```

### Model 4: Price predicted by reviews per month, constructionyear and room_type

*One more model was manually checked to determine whether the factor room_type was a predictor of price, after controlling for construction_year and reviews_per_month. Although we beforehand knew that this predictor would not improve the model, we wanted to add a categorical predictor with interaction effect to the analysis for the purpose of the assignment*

*The estimated average price_usd is 633.4169 for a review_rate_number of 1 when construction year and reviews_per_month are held constant. The estimated difference in average price_usd decreases with 2.5368 for a review_rate_number of 2, compared to a review_rate number of 1, for any construction year or reviews_per_month. However, estimated difference in average is not significant. The only significant estimated difference in average price_usd at an alphalevel of .05 is between review_rate_number 1 compared to review_rate_number of 5. The estimated difference in average price_usd decreases with 10.0145 for a review_rate_number of 5, compared to a review_rate number of 1, for any construction year or reviews_per_month.*  

*When adding an interaction to the model: construction_year and review_rate_number, the results show that there is a significant interaction effect between review_rate_number2 and construction year, which can be interpreted as follows: the strength and direction of the relation between construction_year and price_usd is depends on the review_rate_number, but only review rate number 2.* 

```{r}
#with categorical predictor
model_4 <- lm(price_usd ~ 
                reviews_per_month +
                construction_year +
                review_rate_number,
              data = data)

summary(model_4)

#with interaction effect 
model_5 <- lm(price_usd ~ 
                reviews_per_month +
                construction_year +
                review_rate_number +
                review_rate_number * construction_year,
              data = data)

summary(model_5)

#plot showing the interaction effect 
ggplot(data, aes(construction_year, price_usd, colour = review_rate_number)) +
  stat_smooth(se = FALSE)
```

*After manually checking the two models suggested by the forward stepwise regression approach, the conclusion was drawn that there were no significant predictors for price_usd in this dataset. For the purposes of this assignment however, we will continue with the best model identified by the forward stepwise regression approach: model 3 (price_usd predicted by construction_year and reviews_per_month). For this model, predictions were made about the significance of the regression, but we will now first check the assumptions of this model to check if we can use this model to predict future observations*

# Assumptions

## Visual inspection of Linearity and Homoscedasticity

*After visual inspection of the fitted versus residuals plot the conclusion is drawn that the assumption of linearity is met, because it seems that for any fitted value, the residuals seem to be centered roughly around 0, although there seem to be exceptions for the few fitted values > 650..*
*The assumption of homoscedasticity is harder to interpret, because almost all values are at the left of the plot, but the spread of those residuals does look the same. The few values on the right of the plot, which are far removed from the pattern, might be outliers*

```{r}
plot(fitted(model_3), resid(model_3), col = 'pink', pch = 20,
     xlab = "Fitted", ylab = "Residuals", main = "Data from Model_3")
abline(h = 0, col = "gray", lwd = 2)
```

## Formal testing of Homoscedasticity 

*According to the Breusch-Pagan test, the null-hypothesis "The errors have constant variance about the true model" is not rejected (BP= .989, p = .610), so the assumption of homoscedasticity is met.* 
```{r}
bptest(model_3)
```

## Visual inspection of Normality 

*After visual inspection of the histogram of residuals the conclusion is drawn that the assumption of linearity is violated. A QQ-plot was requested to further investigate the suspected non-normality of errors.The QQ-plot clearly shows a S-shape, which is an indication that the normal distribution has heavy 'tails' or more extreme values. Because of the large sample size, formal testing; like the Shapiro test, could not be executed. These tests are very sensitive when sample sizes exceed 5000.* 
```{r}
hist(resid(model_3),
     xlab   = "Residuals",
     main   = "Histogram of Residuals, model_3",
     col    = "darkorange",
     border = "dodgerblue",
     breaks = 200)

qqnorm(resid(model_3), col = "darkgrey")
qqline(resid(model_3), col = "dodgerblue", lwd = 2)
```

## Testing for multicollineairity 
*The reason why the this assumption is violated, might be due to the extreme amount of observations and the small range of construction year and reviews per month. This reason is expected, because when checking the correlation between those two items, it shows that they are almost uncorrelated (r = .006)*
```{r}
model_3 %>%
  VIF()
cor(data$reviews_per_month, data$construction_year)
```
## Influential observations 

### Outliers 
*Because the plot is not interpretable due to the extreme sample size, the choice was made to only display studentized residuals > 3, which is a common threshold for big datasets, however, there are no studentresiduals bigger than 3 and also no studentresiduals bigger than 2, which is a common threshold for small datasets. Therefor the conclusion was drawn that there are no clear outliers to worry about*
```{r}
model_3 %>%
  rstudent() %>%
  plot()

#Checking if there are student residuals bigger than 2
sum(abs(rstudent(model_3)) > 2)
```

### High leverage 
*in the leverage plot, several observations stand out from other observations. Because the dataset is so big, it is quite hard to identify how many and which observations these are, therefor we calculated the sum of large hatvalues. For small/normal samples the threshold of twice the mean hat value is commonly used, however, because of this large dataset we decided to use a threshold of 3 times the mean hat value. This indicated that there are 1907 points of large leverage.*  
```{r}
model_3 %>%
  hatvalues() %>%
  plot()

sum(hatvalues(model_3) > 3 * mean(hatvalues(model_3)))
```
### Influential Cases 
*The DFBETAS was used to check for influential, and possible problematic observations per regression coefficient. The choice was made to plot influential cases for the intercept, reviews_per_month and construction_year. After visual inspection of the plots we saw that the intercept showed several influential cases. We extracted cases > |.02| based on visual inspection of the dfbetas plot  There are 11 influential cases.*
*Based on visual inspection we also extracted infuential cases > |.05| for reviews per month. 6 influential cases were found.* *The influential cases found for reviewus per month overlap with the influential cases we found in price_usd*
*We did not find influential cases for construction year.*

```{r}
#dfbetasplot intercept
plot(dfbetas(model_3)[,1],
     main = "intercept")

#dfbetasplot reviews_per_month
plot(dfbetas(model_3)[,2],
     main = "reviews_per_month")

#dfbetasplot construction_year
plot(dfbetas(model_3)[,3],
     main = "construction_year")

#extracting outstanding values based on visual inspection of dfbetasplot
dfbetas_observations_intercept <- dfbetas(model_3)[, 1]
outstanding_observations_intercept <- dfbetas_observations_intercept[dfbetas_observations_intercept > 0.02 | dfbetas_observations_intercept < -0.02]
outstanding_observations_intercept

dfbetas_observations_reviews_per_month <- dfbetas(model_3)[, 2]
outstanding_observations_reviews <- dfbetas_observations_reviews_per_month[dfbetas_observations_reviews_per_month > 0.05 | dfbetas_observations_reviews_per_month < -0.05]
outstanding_observations_reviews


```
*We decided to remove 1907 points of large leverage and the influential cases. And to fit the model again to see how the coefficients would change and if this could improve the normality assumption.* 

```{r}
#removal of influential cases. 
rows_to_remove <- c(17809, 24049 ,38036 ,38230, 38479, 41516, 45820, 50503, 65703, 76161, 76692 )

#removal of large leverage 
hat_values <- hatvalues(model_3)
thresholdheadvalues <- 3 * mean(hat_values)
high_leverage_indices <- which(hat_values > thresholdheadvalues)


# Remove rows
data_minus <- data[-rows_to_remove, ]
data_minus <- data_minus[-high_leverage_indices,]

```
```{r}
model_3.1 <- lm(price_usd ~ 
                reviews_per_month +
                construction_year,
                data = data_minus)

summary(model_3.1)
summary(model_3)

#normalitycheck 
qqnorm(resid(model_3.1), col = "darkgrey")
qqline(resid(model_3.1), col = "dodgerblue", lwd = 2)
```

*Final conclusion* 
*After removal of the 1907 points of large leverage and the influential cases their was a slight change in coÃ«fficients noticable. The estimated average of price_usd was 627.8306 instead of 627.9384 in the original model when reviews_per_month and construction_year are held constant. When construction_year increases with one unit, the estimated average price_usd decreases with 0.2853 instead of 0.3066 like the original model, when controlled for reviews per month. This negative correlation is still not significant. When reviews_per_month increases with one unit, the estimated average price_usd increases with 1.1439 instead of 1.1834 like in the original model. This positive relation however is also not significant. The variance that is explained by both reviews_per_month and construction_year is still extremely small (< .01) and even smaller than the original model.*

*Although model meets the assumption of lineairity, homoscedasticity and independence of error and identified influential cases and points with large leverage were removed, this model can not be used to predict future price_usd for airbnb's. This is due to the violation of assumption of normality, which is less of a big problem for bigger samples, but is always wanted for predicting intervals.* 

